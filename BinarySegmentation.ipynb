{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ad72e6",
   "metadata": {},
   "source": [
    "# Binary Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf43bd",
   "metadata": {},
   "source": [
    "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ - —É–∂–µ –≥–æ—Ç–æ–≤–∞—è –∏–≥—Ä–æ–≤–∞—è –ø–ª–æ—â–∞–¥–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –±–∏–Ω–∞—Ä–Ω–æ–π —Å–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –≤ –∫–æ—Ç–æ—Ä–æ–π –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é. –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `dataset` —É–∂–µ –ª–µ–∂–∞—Ç –Ω—É–∂–Ω—ã–µ –¥–∞—Ç–∞—Å–µ—Ç—ã:\n",
    "\n",
    "```bash\n",
    "                datasets/\n",
    "                |-- PipeBoxSegmentation_augmented/\n",
    "                |   |-- images/\n",
    "                |   |   |-- train/\n",
    "                |   |   |-- val/\n",
    "                |   |-- masks/\n",
    "                |   |   |-- train/\n",
    "                |   |   |-- val/\n",
    "                |-- PipeSegmentation_augmented/\n",
    "                |   |-- images/\n",
    "                |   |   |-- train/\n",
    "                |   |   |-- val/\n",
    "                |   |-- masks/\n",
    "                |   |   |-- train/\n",
    "                |   |   |-- val/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c901c1a9",
   "metadata": {},
   "source": [
    "##### **Configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd0642",
   "metadata": {},
   "source": [
    "**Weak Supervised Learning - 5000 images**\n",
    "\n",
    "–¢—É—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞—Ç–∞—Å–µ—Ç, –º–∞—Å–∫–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ –ø–æ–ª—É—á–µ–Ω—ã –ø—Ä–æ—Å—Ç–æ —á–µ—Ä–µ–∑ –∑–∞–ª–∏–≤–∫—É bounding boxes –¥–ª—è YOLO –Ω–∞ –∑–∞–¥–∞—á—É –¥–µ—Ç–µ–∫—Ü–∏–∏. –ü–æ—ç—Ç–æ–º—É *Weak Supervised*. –î–∞–Ω–Ω—ã—Ö –≤ —ç—Ç–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –º–Ω–æ–≥–æ. –ú–æ–∂–µ—Ç–µ –µ–≥–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\n",
    "\n",
    "```bash\n",
    "    datasets/PipeBoxSegmentation_augmented\n",
    "```\n",
    "\n",
    "**Strong Supervised Learning ~ 300 images**\n",
    "\n",
    "–≠—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ, –º–∞—Å–∫–∏ –≤ –∫–æ—Ç–æ—Ä–æ–º –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω—ã —Ä—É–∫–∞–º–∏. –î–∞–Ω–Ω—ã—Ö –≤ —ç—Ç–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –æ—á–µ–Ω—å –º–∞–ª–æ. –ú–æ–∂–µ—Ç–µ –µ–≥–æ —É–≤–∏–¥–µ—Ç—å –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\n",
    "\n",
    "```bash\n",
    "    datasets/PipeSegmentation_augmented\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "765d6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSLConf:    # Weak Supervised Learning Config\n",
    "    def __init__(self):\n",
    "        self.EPOCHS = 10\n",
    "        self.LEARNING_RATE = 1e-4\n",
    "        self.BATCH_SIZE = 4\n",
    "        self.VISUALIZATION_SAMPLES = 20\n",
    "\n",
    "\n",
    "class SSLConf:    # Strong Supervised Learning Config\n",
    "    def __init__(self):\n",
    "        self.EPOCHS = 1\n",
    "        self.LEARNING_RATE = 1e-4\n",
    "        self.BATCH_SIZE = 2\n",
    "        self.VISUALIZATION_SAMPLES = 20\n",
    "\n",
    "WSLCONF = WSLConf()\n",
    "SSLCONF = SSLConf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c4dcf",
   "metadata": {},
   "source": [
    "–û–±—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "057b0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class GeneralConfig:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.RANDOM_SEED = 42\n",
    "        \n",
    "        # --- –õ–£–ß–®–ï –ù–ï –¢–†–û–ì–ê–¢–¨ ---\n",
    "\n",
    "        self.IMAGE_SIZE = (700, 500)\n",
    "        self.IN_CHANNELS = 3\n",
    "        self.CLASSES = 1\n",
    "        \n",
    "        self.MODEL_ENCODER_NAME = \"resnet34\"\n",
    "        self.MODEL_ENCODER_WEIGHTS = \"imagenet\"\n",
    "\n",
    "        self.MLFLOW_TRACKING_URI = os.getenv('MLFLOW_TRACKING_URI')\n",
    "        self.EXPERIMENT_NAME = \"Pipeline Defects Detection\"\n",
    "\n",
    "        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.EVAL_FREQUENCY = 5\n",
    "\n",
    "        self.WEEK_DS_PATH = \"datasets/PipeBoxSegmentation_augmented\"\n",
    "        self.STRONG_DS_PATH = \"datasets/PipeSegmentation_augmented\"\n",
    "\n",
    "\n",
    "GCONF = GeneralConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f77bd",
   "metadata": {},
   "source": [
    "##### **Internal logic code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de63fb",
   "metadata": {},
   "source": [
    "–ö–∞—Å—Ç–æ–º–Ω—ã–π –∫–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "59aa64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    \"\"\"Custom dataset for binary segmentation.\"\"\"\n",
    "\n",
    "    def __init__(self, images_dir, masks_dir, img_size=(700, 500)):\n",
    "        self.images = sorted(glob(os.path.join(images_dir, '*')))\n",
    "        self.masks = sorted(glob(os.path.join(masks_dir, '*')))\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Transformations\n",
    "        self.transform_img = transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.transform_mask = transforms.Compose([\n",
    "            transforms.Resize(self.img_size, interpolation=Image.Resampling.NEAREST),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return a transformed image-mask pair.\"\"\"\n",
    "        img = Image.open(self.images[idx]).convert('RGB')\n",
    "        mask = Image.open(self.masks[idx]).convert('L')\n",
    "\n",
    "        img = self.transform_img(img)\n",
    "        mask = self.transform_mask(mask)\n",
    "\n",
    "        # Binarize mask (0 ‚Äî background, 1 ‚Äî object)\n",
    "        mask = (mask > 0).float()\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557966d3",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "346dc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def check_dataset_dirs(dataset_pash: str) -> bool:\n",
    "\n",
    "    for data_dir in ['images', 'masks']:\n",
    "        for divide_dir in ['train', 'val']:\n",
    "            if not os.path.isdir(os.path.join(dataset_pash, data_dir, divide_dir)):\n",
    "                return False\n",
    "    return True \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12a0fd",
   "metadata": {},
   "source": [
    "–ú–µ—Ç—Ä–∏–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12f3252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(preds: torch.Tensor, targets: torch.Tensor, threshold: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–∏–π IoU –¥–ª—è –±–∞—Ç—á–∞.\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(preds) if preds.min() < 0 or preds.max() > 1 else preds\n",
    "    preds = (preds > threshold).float()\n",
    "\n",
    "    intersection = (preds * targets).sum(dim=(1, 2, 3))\n",
    "    union = (preds + targets - preds * targets).sum(dim=(1, 2, 3))\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    return iou.mean().item()\n",
    "\n",
    "\n",
    "def compute_dice(preds: torch.Tensor, targets: torch.Tensor, threshold: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    –í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–∏–π Dice (F1) –¥–ª—è –±–∞—Ç—á–∞.\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(preds) if preds.min() < 0 or preds.max() > 1 else preds\n",
    "    preds = (preds > threshold).float()\n",
    "\n",
    "    intersection = (preds * targets).sum(dim=(1, 2, 3))\n",
    "    dice = (2 * intersection + 1e-6) / (preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3)) + 1e-6)\n",
    "    return dice.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21b1a1",
   "metadata": {},
   "source": [
    "–í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79183b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _input(message, yes=['y', 'yes'], no=['n','no'], wrong_ans_equals_no=True):\n",
    "\n",
    "    ans = yes + no\n",
    "\n",
    "    inp = input(message)\n",
    "    while inp.lower() not in ans and not wrong_ans_equals_no:\n",
    "        inp = input(message)\n",
    "    \n",
    "    return inp.lower() in yes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047642d",
   "metadata": {},
   "source": [
    "–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "32696f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_predictions(\n",
    "    model,\n",
    "    dataset,\n",
    "    device,\n",
    "    save_path=\"predictions.png\",\n",
    "    num_samples=12,\n",
    "    threshold=0.5,\n",
    "    overlay_alpha=0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –∫—Ä–∞—Å–∏–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:\n",
    "        [Image] | [Ground Truth] | [Overlay (GT=Green, Pred=Red)]\n",
    "\n",
    "    Args:\n",
    "        model: torch.nn.Module ‚Äî –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\n",
    "        dataset: torch.utils.data.Dataset ‚Äî –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö\n",
    "        device: torch.device ‚Äî —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU/GPU)\n",
    "        save_path: str ‚Äî –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "        num_samples: int ‚Äî —Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å\n",
    "        threshold: float ‚Äî –ø–æ—Ä–æ–≥ –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "        overlay_alpha: float ‚Äî –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –æ–≤–µ—Ä–ª–µ—è\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_samples = min(num_samples, len(dataset))\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "\n",
    "    # 3 —Å—Ç–æ–ª–±—Ü–∞: [Image, GT, Overlay]\n",
    "    cols = 3\n",
    "    rows = num_samples\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows))\n",
    "    \n",
    "    # –ï—Å–ª–∏ num_samples == 1, axes –Ω–µ –¥–≤—É–º–µ—Ä–µ–Ω, –∏—Å–ø—Ä–∞–≤–∏–º\n",
    "    if rows == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    # –¶–≤–µ—Ç–∞\n",
    "    gt_color = np.array([0, 255, 0]) / 255.0   # –∑–µ–ª—ë–Ω—ã–π\n",
    "    pred_color = np.array([255, 0, 0]) / 255.0 # –∫—Ä–∞—Å–Ω—ã–π\n",
    "\n",
    "    for row_idx, img_idx in enumerate(indices):\n",
    "        image, mask = dataset[img_idx]\n",
    "        image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "        mask_np = mask.squeeze().cpu().numpy()\n",
    "\n",
    "        # --- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ---\n",
    "        with torch.no_grad():\n",
    "            pred = model(image.unsqueeze(0).to(device))\n",
    "            pred = torch.sigmoid(pred).cpu().squeeze().numpy()\n",
    "            pred_bin = (pred > threshold).astype(np.uint8)\n",
    "\n",
    "        # --- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---\n",
    "        img_orig = np.clip(image_np, 0, 1)\n",
    "\n",
    "        # Ground Truth\n",
    "        img_gt = img_orig.copy()\n",
    "        img_gt[mask_np > 0.5] = (\n",
    "            gt_color * 0.7 + img_gt[mask_np > 0.5] * (1 - 0.7)\n",
    "        )\n",
    "\n",
    "        # Overlay: –∑–µ–ª—ë–Ω—ã–π GT, –∫—Ä–∞—Å–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç\n",
    "        img_overlay = img_orig.copy()\n",
    "        img_overlay[mask_np > 0.5] = (\n",
    "            gt_color * overlay_alpha + img_overlay[mask_np > 0.5] * (1 - overlay_alpha)\n",
    "        )\n",
    "        img_overlay[pred_bin > 0.5] = (\n",
    "            pred_color * overlay_alpha + img_overlay[pred_bin > 0.5] * (1 - overlay_alpha)\n",
    "        )\n",
    "\n",
    "        # --- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ ---\n",
    "        axes[row_idx, 0].imshow(img_orig)\n",
    "        axes[row_idx, 0].set_title(f\"Image {img_idx}\", fontsize=10)\n",
    "        axes[row_idx, 0].axis(\"off\")\n",
    "\n",
    "        axes[row_idx, 1].imshow(img_gt)\n",
    "        axes[row_idx, 1].set_title(\"Ground Truth\", fontsize=10)\n",
    "        axes[row_idx, 1].axis(\"off\")\n",
    "\n",
    "        axes[row_idx, 2].imshow(img_overlay)\n",
    "        axes[row_idx, 2].set_title(\"Overlay (GT=Green, Pred=Red)\", fontsize=10)\n",
    "        axes[row_idx, 2].axis(\"off\")\n",
    "\n",
    "    # --- –û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ ---\n",
    "    fig.suptitle(\"Model Predictions Overview\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved visualization to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab59bc",
   "metadata": {},
   "source": [
    "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b135358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "def save_model(model, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å PyTorch –≤ –ø–∞–ø–∫—É 'models' —Å –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º –≤ –∏–º–µ–Ω–∏.\n",
    "    \n",
    "    Args:\n",
    "        model: —ç–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ PyTorch\n",
    "        model_name (str): –±–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)\n",
    "    \n",
    "    Returns:\n",
    "        str: –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É\n",
    "    \"\"\"\n",
    "    # 1. –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É models, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç\n",
    "    save_folder = \"models\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –º–µ—Ç–∫—É –≤—Ä–µ–º–µ–Ω–∏\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 3. –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞: models/model_name_20251108_122430.pth\n",
    "    filename = f\"{model_name}_{timestamp}.pth\"\n",
    "    save_path = os.path.join(save_folder, filename)\n",
    "    \n",
    "    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º state_dict –º–æ–¥–µ–ª–∏\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    print(f\"Model saved localy: {save_path}\")\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7d58e",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, CFG):\n",
    "\n",
    "    train_type = 'Weak' if isinstance(CFG, WSLConf) else 'Strong'\n",
    "\n",
    "    print(\"# ==================================================\")\n",
    "    print(f\"# {train_type} Supervised Learning\")\n",
    "    print(\"# ==================================================\")\n",
    "\n",
    "    print(\"\\nLoading dataset...\", end=' ')\n",
    "\n",
    "    # –î–∞, —Ç—É—Ç —Å–ª–æ–∂–Ω–æ–≤–∞—Ç–æ...\n",
    "    if train_type == 'Weak':\n",
    "        train_ds = SegmentationDataset(\n",
    "            os.path.join(GCONF.WEEK_DS_PATH, 'images', 'train'), \n",
    "            os.path.join(GCONF.WEEK_DS_PATH, 'masks', 'train'), \n",
    "            GCONF.IMAGE_SIZE\n",
    "        )\n",
    "        val_ds = SegmentationDataset(\n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'images', 'train'), \n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'masks', 'train'), \n",
    "            GCONF.IMAGE_SIZE\n",
    "        )\n",
    "    else:\n",
    "        train_ds = SegmentationDataset(\n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'images', 'train'), \n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'masks', 'train'), \n",
    "            GCONF.IMAGE_SIZE\n",
    "        )\n",
    "        val_ds = SegmentationDataset(\n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'images', 'val'), \n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'masks', 'val'), \n",
    "            GCONF.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    print(\"success\\n\")\n",
    "\n",
    "    run_name = f\"Binary Semantic Segmentation ({train_type})\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "        print(f\"Start run {run_name} with params:\")\n",
    "        hyperparams = vars(CFG) | vars(GCONF) | {\"optimizer\": optimizer.__class__.__name__, \"criterion\": criterion.__class__.__name__}\n",
    "        for key, value in hyperparams.items():\n",
    "            print(f\"\\t{key:<{30}} {str(value):<{30}}\")\n",
    "        print()\n",
    "        mlflow.log_params(hyperparams)\n",
    "\n",
    "        epochs = CFG.EPOCHS     # –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞\n",
    "        val_steps = max(1, len(train_loader) // GCONF.EVAL_FREQUENCY)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # --- Train ---\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "            for imgs, masks in progress_bar:\n",
    "                imgs, masks = imgs.to(GCONF.DEVICE), masks.to(GCONF.DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, masks)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # --- –í–∞–ª–∏–¥–∞—Ü–∏—è, –¥–∞ –ø–æ—Å—Ä–µ–¥–∏ —ç–ø–æ—Ö–∏, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç–ø–æ—Ö–∏ –¥–æ–ª–≥–∏–µ ---\n",
    "                if (progress_bar.n + 1) % val_steps == 0 or (progress_bar.n + 1) == progress_bar.total:\n",
    "                    model.eval()\n",
    "                    val_loss, val_iou, val_dice = 0.0, 0.0, 0.0\n",
    "                    with torch.no_grad():\n",
    "                        for v_imgs, v_masks in val_loader:\n",
    "                            v_imgs, v_masks = v_imgs.to(GCONF.DEVICE), v_masks.to(GCONF.DEVICE)\n",
    "                            v_preds = model(v_imgs)\n",
    "\n",
    "                            v_loss = criterion(v_preds, v_masks)\n",
    "                            val_loss += v_loss.item()\n",
    "                            val_iou += compute_iou(v_preds, v_masks)\n",
    "                            val_dice += compute_dice(v_preds, v_masks)\n",
    "\n",
    "                    avg_val_loss = val_loss / len(val_loader)\n",
    "                    avg_val_iou = val_iou / len(val_loader)\n",
    "                    avg_val_dice = val_dice / len(val_loader)\n",
    "                    avg_train_loss = total_loss / (progress_bar.n + 1)\n",
    "\n",
    "                    progress_bar.set_postfix({\n",
    "                        \"train_loss\": f\"{avg_train_loss:.4f}\",\n",
    "                        \"val_loss\": f\"{avg_val_loss:.4f}\",\n",
    "                        \"IoU\": f\"{avg_val_iou:.4f}\",\n",
    "                        \"Dice\": f\"{avg_val_dice:.4f}\"\n",
    "                    })\n",
    "\n",
    "                    mlflow.log_metrics({\n",
    "                        \"train_loss\": avg_train_loss,\n",
    "                        \"val_loss\": avg_val_loss,\n",
    "                        \"val_iou\": avg_val_iou,\n",
    "                        \"val_dice\": avg_val_dice\n",
    "                    }, step=epoch * len(train_loader) + progress_bar.n + 1)\n",
    "\n",
    "        print(\"Training completed!\\n\")\n",
    "        \n",
    "        # --- Save Model ---\n",
    "        save_model(model, f\"unet_bin_seg_dice{avg_val_dice:.4f}_iou{val_iou:.4f}\")\n",
    "\n",
    "        save_model_to_server = _input(\"Save the model to the server (Y/n)? \")\n",
    "        if save_model_to_server:\n",
    "            print(\"Saving model...\", end=' ')\n",
    "            model_path = \"model\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            mlflow.log_artifact(model_path)\n",
    "            mlflow.pytorch.log_model(model, name=\"UNetBimarySemanticSegmentation\")\n",
    "            print(\"success\")\n",
    "\n",
    "        # --- Visualize ---\n",
    "        print(\"Making visuzlization...\", end=' ')\n",
    "        vis_path = \"predictions.png\"\n",
    "        visualize_predictions(model, val_ds, GCONF.DEVICE, save_path=vis_path, num_samples=CFG.VISUALIZATION_SAMPLES)\n",
    "        mlflow.log_artifact(vis_path)\n",
    "        print(\"success\")\n",
    "\n",
    "        print(\"\\n# Weak Supervised Learning Finish\")\n",
    "        print(\"# ==================================================\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd30a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ==================================================\n",
      "# Creating Binary Semantic Segmentation Model\n",
      "# ==================================================\n",
      "Connecting to MLFlow... success\n",
      "Loading weights 'imagenet'...  success\n",
      "# ==================================================\n",
      "# Strong Supervised Learning\n",
      "# ==================================================\n",
      "\n",
      "Loading dataset... success\n",
      "\n",
      "Start run Binary Semantic Segmentation (Strong) with params:\n",
      "\tEPOCHS                         1                             \n",
      "\tLEARNING_RATE                  0.0001                        \n",
      "\tBATCH_SIZE                     2                             \n",
      "\tVISUALIZATION_SAMPLES          20                            \n",
      "\tRANDOM_SEED                    42                            \n",
      "\tIMAGE_SIZE                     (700, 500)                    \n",
      "\tIN_CHANNELS                    3                             \n",
      "\tCLASSES                        1                             \n",
      "\tMODEL_ENCODER_NAME             resnet34                      \n",
      "\tMODEL_ENCODER_WEIGHTS          imagenet                      \n",
      "\tMLFLOW_TRACKING_URI            http://158.160.195.83:5001    \n",
      "\tEXPERIMENT_NAME                Pipeline Defects Detection    \n",
      "\tDEVICE                         cuda                          \n",
      "\tEVAL_FREQUENCY                 5                             \n",
      "\tWEEK_DS_PATH                   datasets/PipeBoxSegmentation_augmented\n",
      "\tSTRONG_DS_PATH                 datasets/PipeSegmentation_augmented\n",
      "\toptimizer                      Adam                          \n",
      "\tcriterion                      BCEWithLogitsLoss             \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "\n",
      "Model saved localy: models\\unet_bin_seg_dice0.3148888595864016_iou5.720966298286559_20251108_124203.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making visuzlization... Saved visualization to: predictions.png\n",
      "success\n",
      "\n",
      "# Weak Supervised Learning Finish\n",
      "# ==================================================\n",
      "üèÉ View run Binary Semantic Segmentation (Strong) at: http://158.160.195.83:5001/#/experiments/2/runs/9f45f66b331f43f58f9eb653fc3dfc1f\n",
      "üß™ View experiment at: http://158.160.195.83:5001/#/experiments/2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from torch import nn\n",
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "print(\"# ==================================================\")\n",
    "print(\"# Creating Binary Semantic Segmentation Model\")\n",
    "print(\"# ==================================================\")\n",
    "\n",
    "\n",
    "USERNAME = input(\"Enter your name: \")\n",
    "os.environ[\"USER\"] = USERNAME\n",
    "\n",
    "print(\"Connecting to MLFlow...\", end=' ')\n",
    "\n",
    "mlflow.set_tracking_uri(GCONF.MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(GCONF.EXPERIMENT_NAME)\n",
    "\n",
    "print('success')\n",
    "\n",
    "load_new_model = _input(\"Load model (Y/n)? \")\n",
    "if load_new_model:\n",
    "    model = Unet(\n",
    "        encoder_name=GCONF.MODEL_ENCODER_NAME,\n",
    "        encoder_weights=None,\n",
    "        in_channels=GCONF.IN_CHANNELS,\n",
    "        classes=GCONF.CLASSES\n",
    "    )\n",
    "    model.to(GCONF.DEVICE)\n",
    "\n",
    "    model_name = input(\"Enter model name in models/ directory: \").split('.')[0] + '.pth'\n",
    "    model_path = os.path.join('models', model_name)\n",
    "\n",
    "    print(f\"Loading '{model_path}'... \", end=' ')\n",
    "    \n",
    "    state_dict = torch.load(model_path, map_location=GCONF.DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    print(\"success\")\n",
    "else:\n",
    "    print(f\"Loading weights '{GCONF.MODEL_ENCODER_WEIGHTS}'... \", end=' ')\n",
    "\n",
    "    model = Unet(\n",
    "        encoder_name=GCONF.MODEL_ENCODER_NAME,\n",
    "        encoder_weights=GCONF.MODEL_ENCODER_WEIGHTS,\n",
    "        in_channels=GCONF.IN_CHANNELS,\n",
    "        classes=GCONF.CLASSES\n",
    "    )\n",
    "    model.to(GCONF.DEVICE)\n",
    "\n",
    "    print(\"success\")\n",
    "\n",
    "# --- Freeze encoder (transfer learning) ---\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "weak_supervised_learning = _input(\"Choose type of learning (Weak[w]/Strong[s])\", ['w', 'weak'], ['s','strong'], False)\n",
    "\n",
    "if weak_supervised_learning:\n",
    "    \n",
    "    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: —Ç–æ–ª—å–∫–æ –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–¥–µ–∫–æ–¥–µ—Ä)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=WSLCONF.LEARNING_RATE\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()  # –î–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "\n",
    "    train(model, optimizer=optimizer, criterion=criterion, CFG=WSLCONF)\n",
    "else:\n",
    "\n",
    "    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: —Ç–æ–ª—å–∫–æ –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–¥–µ–∫–æ–¥–µ—Ä)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=SSLCONF.LEARNING_RATE\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()  # –î–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
    "\n",
    "    train(model, optimizer=optimizer, criterion=criterion, CFG=SSLCONF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
