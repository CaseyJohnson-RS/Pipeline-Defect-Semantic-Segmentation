{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ad72e6",
   "metadata": {},
   "source": [
    "# Binary Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf43bd",
   "metadata": {},
   "source": [
    "Этот ноутбук - уже готовая игровая площадка для создания модели бинарной сематической сегментации, в которой можно менять только конфигурацию. Перед запуском убедитесь, что в директории `dataset` уже лежат нужные датасеты:\n",
    "\n",
    "```bash\n",
    "                datasets/\n",
    "                |-- PipeBoxSegmentation_augmented/\n",
    "                |   |-- images/\n",
    "                |   |   |-- train/\n",
    "                |   |   |-- val/\n",
    "                |   |-- masks/\n",
    "                |   |   |-- train/\n",
    "                |   |   |-- val/\n",
    "                |-- PipeSegmentation_augmented/\n",
    "                |   |-- images/\n",
    "                |   |   |-- train/\n",
    "                |   |   |-- val/\n",
    "                |   |-- masks/\n",
    "                |   |   |-- train/\n",
    "                |   |   |-- val/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb12e83",
   "metadata": {},
   "source": [
    "Проверка доступности вычислений на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA доступен:\", torch.cuda.is_available())\n",
    "print(\"Число GPU:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Имя GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Версия CUDA:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c901c1a9",
   "metadata": {},
   "source": [
    "##### **Configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dd0642",
   "metadata": {},
   "source": [
    "**Weak Supervised Learning - 5000 images**\n",
    "\n",
    "Тут используется датасет, маски для сегментации которого получены просто через заливку bounding boxes для YOLO на задачу детекции. Поэтому *Weak Supervised*. Данных в этом датасете много. Можете его посмотреть в директории:\n",
    "\n",
    "```bash\n",
    "    datasets/PipeBoxSegmentation_augmented\n",
    "```\n",
    "\n",
    "**Strong Supervised Learning ~ 300 images**\n",
    "\n",
    "Это обучение происходит на датасете, маски в котором нарисованы руками. Данных в этом датасете очень мало. Можете его увидеть в директории:\n",
    "\n",
    "```bash\n",
    "    datasets/PipeSegmentation_augmented\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSLConf:    # Weak Supervised Learning Config\n",
    "    def __init__(self):\n",
    "        self.EPOCHS = 10\n",
    "        self.LEARNING_RATE = 1e-4\n",
    "        self.BATCH_SIZE = 4\n",
    "        self.VISUALIZATION_SAMPLES = 20\n",
    "\n",
    "\n",
    "class SSLConf:    # Strong Supervised Learning Config\n",
    "    def __init__(self):\n",
    "        self.EPOCHS = 1\n",
    "        self.LEARNING_RATE = 1e-4\n",
    "        self.BATCH_SIZE = 2\n",
    "        self.VISUALIZATION_SAMPLES = 20\n",
    "\n",
    "WSLCONF = WSLConf()\n",
    "SSLCONF = SSLConf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c4dcf",
   "metadata": {},
   "source": [
    "Общая конфигурация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057b0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class GeneralConfig:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.RANDOM_SEED = 42\n",
    "        \n",
    "        # --- ЛУЧШЕ НЕ ТРОГАТЬ ---\n",
    "\n",
    "        self.IMAGE_SIZE = (700, 500)\n",
    "        self.IN_CHANNELS = 3\n",
    "        self.CLASSES = 1\n",
    "        \n",
    "        self.MODEL_ENCODER_NAME = \"resnet34\"\n",
    "        self.MODEL_ENCODER_WEIGHTS = \"imagenet\"\n",
    "\n",
    "        self.MLFLOW_TRACKING_URI = os.getenv('MLFLOW_TRACKING_URI')\n",
    "        self.EXPERIMENT_NAME = \"Pipeline Defects Detection\"\n",
    "\n",
    "        self.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.EVAL_FREQUENCY = 5\n",
    "\n",
    "        self.WEEK_DS_PATH = \"datasets/PipeBoxSegmentation_augmented\"\n",
    "        self.STRONG_DS_PATH = \"datasets/PipeSegmentation_augmented\"\n",
    "\n",
    "\n",
    "GCONF = GeneralConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f77bd",
   "metadata": {},
   "source": [
    "##### **Internal logic code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de63fb",
   "metadata": {},
   "source": [
    "Кастомный класс датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from glob import glob\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    \"\"\"Custom dataset for binary segmentation.\"\"\"\n",
    "\n",
    "    def __init__(self, images_dir, masks_dir, img_size=(700, 500)):\n",
    "        self.images = sorted(glob(os.path.join(images_dir, '*')))\n",
    "        self.masks = sorted(glob(os.path.join(masks_dir, '*')))\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # Transformations\n",
    "        self.transform_img = transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.transform_mask = transforms.Compose([\n",
    "            transforms.Resize(self.img_size, interpolation=Image.Resampling.NEAREST),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return a transformed image-mask pair.\"\"\"\n",
    "        img = Image.open(self.images[idx]).convert('RGB')\n",
    "        mask = Image.open(self.masks[idx]).convert('L')\n",
    "\n",
    "        img = self.transform_img(img)\n",
    "        mask = self.transform_mask(mask)\n",
    "\n",
    "        # Binarize mask (0 — background, 1 — object)\n",
    "        mask = (mask > 0).float()\n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557966d3",
   "metadata": {},
   "source": [
    "Проверка правильности структуры директорий датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346dc764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def check_dataset_dirs(dataset_pash: str) -> bool:\n",
    "\n",
    "    for data_dir in ['images', 'masks']:\n",
    "        for divide_dir in ['train', 'val']:\n",
    "            if not os.path.isdir(os.path.join(dataset_pash, data_dir, divide_dir)):\n",
    "                return False\n",
    "    return True \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a12a0fd",
   "metadata": {},
   "source": [
    "Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(preds: torch.Tensor, targets: torch.Tensor, threshold: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет средний IoU для батча.\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(preds) if preds.min() < 0 or preds.max() > 1 else preds\n",
    "    preds = (preds > threshold).float()\n",
    "\n",
    "    intersection = (preds * targets).sum(dim=(1, 2, 3))\n",
    "    union = (preds + targets - preds * targets).sum(dim=(1, 2, 3))\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    return iou.mean().item()\n",
    "\n",
    "\n",
    "def compute_dice(preds: torch.Tensor, targets: torch.Tensor, threshold: float = 0.5) -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет средний Dice (F1) для батча.\n",
    "    \"\"\"\n",
    "    preds = torch.sigmoid(preds) if preds.min() < 0 or preds.max() > 1 else preds\n",
    "    preds = (preds > threshold).float()\n",
    "\n",
    "    intersection = (preds * targets).sum(dim=(1, 2, 3))\n",
    "    dice = (2 * intersection + 1e-6) / (preds.sum(dim=(1, 2, 3)) + targets.sum(dim=(1, 2, 3)) + 1e-6)\n",
    "    return dice.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21b1a1",
   "metadata": {},
   "source": [
    "Ввод данных с клавиатуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79183b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _input(message, yes=['y', 'yes'], no=['n','no'], wrong_ans_equals_no=True):\n",
    "\n",
    "    ans = yes + no\n",
    "\n",
    "    inp = input(message)\n",
    "    while inp.lower() not in ans and not wrong_ans_equals_no:\n",
    "        inp = input(message)\n",
    "    \n",
    "    return inp.lower() in yes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047642d",
   "metadata": {},
   "source": [
    "Визуализация работы модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32696f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_predictions(\n",
    "    model,\n",
    "    dataset,\n",
    "    device,\n",
    "    save_path=\"predictions.png\",\n",
    "    num_samples=12,\n",
    "    threshold=0.5,\n",
    "    overlay_alpha=0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Визуализирует результаты сегментации в красивом формате:\n",
    "        [Image] | [Ground Truth] | [Overlay (GT=Green, Pred=Red)]\n",
    "\n",
    "    Args:\n",
    "        model: torch.nn.Module — обученная модель\n",
    "        dataset: torch.utils.data.Dataset — набор данных\n",
    "        device: torch.device — устройство (CPU/GPU)\n",
    "        save_path: str — путь для сохранения визуализации\n",
    "        num_samples: int — сколько примеров отобразить\n",
    "        threshold: float — порог бинаризации предсказаний\n",
    "        overlay_alpha: float — прозрачность оверлея\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_samples = min(num_samples, len(dataset))\n",
    "    indices = random.sample(range(len(dataset)), num_samples)\n",
    "\n",
    "    # 3 столбца: [Image, GT, Overlay]\n",
    "    cols = 3\n",
    "    rows = num_samples\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows))\n",
    "    \n",
    "    # Если num_samples == 1, axes не двумерен, исправим\n",
    "    if rows == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    # Цвета\n",
    "    gt_color = np.array([0, 255, 0]) / 255.0   # зелёный\n",
    "    pred_color = np.array([255, 0, 0]) / 255.0 # красный\n",
    "\n",
    "    for row_idx, img_idx in enumerate(indices):\n",
    "        image, mask = dataset[img_idx]\n",
    "        image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "        mask_np = mask.squeeze().cpu().numpy()\n",
    "\n",
    "        # --- Предсказание ---\n",
    "        with torch.no_grad():\n",
    "            pred = model(image.unsqueeze(0).to(device))\n",
    "            pred = torch.sigmoid(pred).cpu().squeeze().numpy()\n",
    "            pred_bin = (pred > threshold).astype(np.uint8)\n",
    "\n",
    "        # --- Изображения ---\n",
    "        img_orig = np.clip(image_np, 0, 1)\n",
    "\n",
    "        # Ground Truth\n",
    "        img_gt = img_orig.copy()\n",
    "        img_gt[mask_np > 0.5] = (\n",
    "            gt_color * 0.7 + img_gt[mask_np > 0.5] * (1 - 0.7)\n",
    "        )\n",
    "\n",
    "        # Overlay: зелёный GT, красный предикт\n",
    "        img_overlay = img_orig.copy()\n",
    "        img_overlay[mask_np > 0.5] = (\n",
    "            gt_color * overlay_alpha + img_overlay[mask_np > 0.5] * (1 - overlay_alpha)\n",
    "        )\n",
    "        img_overlay[pred_bin > 0.5] = (\n",
    "            pred_color * overlay_alpha + img_overlay[pred_bin > 0.5] * (1 - overlay_alpha)\n",
    "        )\n",
    "\n",
    "        # --- Построение ---\n",
    "        axes[row_idx, 0].imshow(img_orig)\n",
    "        axes[row_idx, 0].set_title(f\"Image {img_idx}\", fontsize=10)\n",
    "        axes[row_idx, 0].axis(\"off\")\n",
    "\n",
    "        axes[row_idx, 1].imshow(img_gt)\n",
    "        axes[row_idx, 1].set_title(\"Ground Truth\", fontsize=10)\n",
    "        axes[row_idx, 1].axis(\"off\")\n",
    "\n",
    "        axes[row_idx, 2].imshow(img_overlay)\n",
    "        axes[row_idx, 2].set_title(\"Overlay (GT=Green, Pred=Red)\", fontsize=10)\n",
    "        axes[row_idx, 2].axis(\"off\")\n",
    "\n",
    "    # --- Оформление ---\n",
    "    fig.suptitle(\"Model Predictions Overview\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\", dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved visualization to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cab59bc",
   "metadata": {},
   "source": [
    "Сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "def save_model(model, model_name=\"model\"):\n",
    "    \"\"\"\n",
    "    Сохраняет модель PyTorch в папку 'models' с датой и временем в имени.\n",
    "    \n",
    "    Args:\n",
    "        model: экземпляр модели PyTorch\n",
    "        model_name (str): базовое имя файла (без расширения)\n",
    "    \n",
    "    Returns:\n",
    "        str: полный путь к сохранённому файлу\n",
    "    \"\"\"\n",
    "    # 1. Создаём папку models, если её нет\n",
    "    save_folder = \"models\"\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    # 2. Формируем метку времени\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 3. Формируем имя файла: models/model_name_20251108_122430.pth\n",
    "    filename = f\"{model_name}_{timestamp}.pth\"\n",
    "    save_path = os.path.join(save_folder, filename)\n",
    "    \n",
    "    # 4. Сохраняем state_dict модели\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    print(f\"Model saved localy: {save_path}\")\n",
    "    return save_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7d58e",
   "metadata": {},
   "source": [
    "Функция обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(model, optimizer, criterion, CFG):\n",
    "\n",
    "    train_type = 'Weak' if isinstance(CFG, WSLConf) else 'Strong'\n",
    "\n",
    "    print(\"# ==================================================\")\n",
    "    print(f\"# {train_type} Supervised Learning\")\n",
    "    print(\"# ==================================================\")\n",
    "\n",
    "    print(\"\\nLoading dataset...\", end=' ')\n",
    "\n",
    "    # Да, тут сложновато...\n",
    "    if train_type == 'Weak':\n",
    "        train_ds = SegmentationDataset(\n",
    "            os.path.join(GCONF.WEEK_DS_PATH, 'images', 'train'), \n",
    "            os.path.join(GCONF.WEEK_DS_PATH, 'masks', 'train'), \n",
    "            GCONF.IMAGE_SIZE\n",
    "        )\n",
    "        val_ds = SegmentationDataset(\n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'images', 'train'), \n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'masks', 'train'), \n",
    "            GCONF.IMAGE_SIZE\n",
    "        )\n",
    "    else:\n",
    "        train_ds = SegmentationDataset(\n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'images', 'train'), \n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'masks', 'train'), \n",
    "            GCONF.IMAGE_SIZE\n",
    "        )\n",
    "        val_ds = SegmentationDataset(\n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'images', 'val'), \n",
    "            os.path.join(GCONF.STRONG_DS_PATH, 'masks', 'val'), \n",
    "            GCONF.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=CFG.BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    print(\"success\\n\")\n",
    "\n",
    "    run_name = f\"Binary Semantic Segmentation ({train_type})\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "\n",
    "        # Логируем параметры\n",
    "        print(f\"Start run {run_name} with params:\")\n",
    "        hyperparams = vars(CFG) | vars(GCONF) | {\"optimizer\": optimizer.__class__.__name__, \"criterion\": criterion.__class__.__name__}\n",
    "        for key, value in hyperparams.items():\n",
    "            print(f\"\\t{key:<{30}} {str(value):<{30}}\")\n",
    "        print()\n",
    "        mlflow.log_params(hyperparams)\n",
    "\n",
    "        epochs = CFG.EPOCHS     # Для удобства\n",
    "        val_steps = max(1, len(train_loader) // GCONF.EVAL_FREQUENCY)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # --- Train ---\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "            for imgs, masks in progress_bar:\n",
    "                imgs, masks = imgs.to(GCONF.DEVICE), masks.to(GCONF.DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                preds = model(imgs)\n",
    "                loss = criterion(preds, masks)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # --- Валидация, да посреди эпохи, потому что эпохи долгие ---\n",
    "                if (progress_bar.n + 1) % val_steps == 0 or (progress_bar.n + 1) == progress_bar.total:\n",
    "                    model.eval()\n",
    "                    val_loss, val_iou, val_dice = 0.0, 0.0, 0.0\n",
    "                    with torch.no_grad():\n",
    "                        for v_imgs, v_masks in val_loader:\n",
    "                            v_imgs, v_masks = v_imgs.to(GCONF.DEVICE), v_masks.to(GCONF.DEVICE)\n",
    "                            v_preds = model(v_imgs)\n",
    "\n",
    "                            v_loss = criterion(v_preds, v_masks)\n",
    "                            val_loss += v_loss.item()\n",
    "                            val_iou += compute_iou(v_preds, v_masks)\n",
    "                            val_dice += compute_dice(v_preds, v_masks)\n",
    "\n",
    "                    avg_val_loss = val_loss / len(val_loader)\n",
    "                    avg_val_iou = val_iou / len(val_loader)\n",
    "                    avg_val_dice = val_dice / len(val_loader)\n",
    "                    avg_train_loss = total_loss / (progress_bar.n + 1)\n",
    "\n",
    "                    progress_bar.set_postfix({\n",
    "                        \"train_loss\": f\"{avg_train_loss:.4f}\",\n",
    "                        \"val_loss\": f\"{avg_val_loss:.4f}\",\n",
    "                        \"IoU\": f\"{avg_val_iou:.4f}\",\n",
    "                        \"Dice\": f\"{avg_val_dice:.4f}\"\n",
    "                    })\n",
    "\n",
    "                    mlflow.log_metrics({\n",
    "                        \"train_loss\": avg_train_loss,\n",
    "                        \"val_loss\": avg_val_loss,\n",
    "                        \"val_iou\": avg_val_iou,\n",
    "                        \"val_dice\": avg_val_dice\n",
    "                    }, step=epoch * len(train_loader) + progress_bar.n + 1)\n",
    "\n",
    "        print(\"Training completed!\\n\")\n",
    "        \n",
    "        # --- Save Model ---\n",
    "        save_model(model, f\"unet_bin_seg_dice{avg_val_dice:.4f}_iou{val_iou:.4f}\")\n",
    "\n",
    "        save_model_to_server = _input(\"Save the model to the server (Y/n)? \")\n",
    "        if save_model_to_server:\n",
    "            print(\"Saving model...\", end=' ')\n",
    "            model_path = \"model\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            mlflow.log_artifact(model_path)\n",
    "            mlflow.pytorch.log_model(model, name=\"UNetBimarySemanticSegmentation\")\n",
    "            print(\"success\")\n",
    "\n",
    "        # --- Visualize ---\n",
    "        print(\"Making visuzlization...\", end=' ')\n",
    "        vis_path = \"predictions.png\"\n",
    "        visualize_predictions(model, val_ds, GCONF.DEVICE, save_path=vis_path, num_samples=CFG.VISUALIZATION_SAMPLES)\n",
    "        mlflow.log_artifact(vis_path)\n",
    "        print(\"success\")\n",
    "\n",
    "        print(\"\\n# Weak Supervised Learning Finish\")\n",
    "        print(\"# ==================================================\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd30a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from torch import nn\n",
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "print(\"# ==================================================\")\n",
    "print(\"# Creating Binary Semantic Segmentation Model\")\n",
    "print(\"# ==================================================\")\n",
    "\n",
    "\n",
    "USERNAME = input(\"Enter your name: \")\n",
    "os.environ[\"USER\"] = USERNAME\n",
    "\n",
    "print(\"Connecting to MLFlow...\", end=' ')\n",
    "\n",
    "mlflow.set_tracking_uri(GCONF.MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(GCONF.EXPERIMENT_NAME)\n",
    "\n",
    "print('success')\n",
    "\n",
    "load_new_model = _input(\"Load model (Y/n)? \")\n",
    "if load_new_model:\n",
    "    model = Unet(\n",
    "        encoder_name=GCONF.MODEL_ENCODER_NAME,\n",
    "        encoder_weights=None,\n",
    "        in_channels=GCONF.IN_CHANNELS,\n",
    "        classes=GCONF.CLASSES\n",
    "    )\n",
    "    model.to(GCONF.DEVICE)\n",
    "\n",
    "    model_name = input(\"Enter model name in models/ directory: \").split('.')[0] + '.pth'\n",
    "    model_path = os.path.join('models', model_name)\n",
    "\n",
    "    print(f\"Loading '{model_path}'... \", end=' ')\n",
    "    \n",
    "    state_dict = torch.load(model_path, map_location=GCONF.DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    print(\"success\")\n",
    "else:\n",
    "    print(f\"Loading weights '{GCONF.MODEL_ENCODER_WEIGHTS}'... \", end=' ')\n",
    "\n",
    "    model = Unet(\n",
    "        encoder_name=GCONF.MODEL_ENCODER_NAME,\n",
    "        encoder_weights=GCONF.MODEL_ENCODER_WEIGHTS,\n",
    "        in_channels=GCONF.IN_CHANNELS,\n",
    "        classes=GCONF.CLASSES\n",
    "    )\n",
    "    model.to(GCONF.DEVICE)\n",
    "\n",
    "    print(\"success\")\n",
    "\n",
    "# --- Freeze encoder (transfer learning) ---\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "weak_supervised_learning = _input(\"Choose type of learning (Weak [ W ] / Strong [ S ] )\", ['w', 'weak'], ['s','strong'], False)\n",
    "\n",
    "if weak_supervised_learning:\n",
    "    \n",
    "    # Оптимизатор: только обучаемые параметры (декодер)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=WSLCONF.LEARNING_RATE\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Для бинарной сегментации\n",
    "\n",
    "    train(model, optimizer=optimizer, criterion=criterion, CFG=WSLCONF)\n",
    "else:\n",
    "\n",
    "    # Оптимизатор: только обучаемые параметры (декодер)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=SSLCONF.LEARNING_RATE\n",
    "    )\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Для бинарной сегментации\n",
    "\n",
    "    train(model, optimizer=optimizer, criterion=criterion, CFG=SSLCONF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
