import os
import json
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
import cv2
import torch
from torch.utils.data import Dataset
import random
import sys

PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../"))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
from src.models.factories import load_unet_attention  # noqa: E402

# ============== CONFIGURATION ==============
DATASET_NAME = input("Enter dataset name: ")
SOURCE_DIR = Path(f"datasets/{DATASET_NAME}")
BASELINE_DIR = Path(f"datasets/{DATASET_NAME}_BASELINE")
OUTPUT_DIR = Path(f"datasets/{DATASET_NAME}_H")  # –ë—É–¥–µ—Ç –¥–æ–ø–æ–ª–Ω–µ–Ω –∑–Ω–∞—á–µ–Ω–∏–µ–º alpha

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –∏ —É–ª—É—á—à–µ–Ω–∏—è –º–∞—Å–æ–∫
ALPHA = 0.7  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω—ã—Ö –º–∞—Å–æ–∫
MODEL_INPUT_SIZE = (702, 512)  # –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
RANDOM_SEED = 42
TRAIN_VAL_SPLIT = 0.85  # 85% –¥–ª—è train
NUM_AUGMENTATIONS = 3   # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ–¥–Ω–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ
# ============================================

class ImageMaskDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –º–∞—Å–æ–∫"""
    def __init__(self, image_paths, mask_paths, transform=None):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.transform = transform
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        image = cv2.imread(str(self.image_paths[idx]))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(str(self.mask_paths[idx]), cv2.IMREAD_GRAYSCALE)
        
        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']
        
        return image, mask, self.image_paths[idx]

def parse_polygon(annotation_str):
    """–ü–∞—Ä—Å–∏—Ç JSON-—Å—Ç—Ä–æ–∫—É —Å –ø–æ–ª–∏–≥–æ–Ω–æ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã"""
    try:
        cleaned = annotation_str.replace('""', '"')
        data = json.loads(cleaned)
        if data['name'] == 'polygon':
            return data['all_points_x'], data['all_points_y']
        return None, None
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ–ª–∏–≥–æ–Ω–∞: {e}")
        return None, None

def create_mask_from_polygon(image_shape, points_x, points_y):
    """–°–æ–∑–¥–∞–µ—Ç –±–∏–Ω–∞—Ä–Ω—É—é –º–∞—Å–∫—É –∏–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø–æ–ª–∏–≥–æ–Ω–∞"""
    mask = np.zeros(image_shape[:2], dtype=np.uint8)
    points = np.array(list(zip(points_x, points_y)), dtype=np.int32)
    cv2.fillPoly(mask, [points], color=255)
    return mask

def copy_or_create_dirs(*dirs):
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç"""
    for dir_path in dirs:
        dir_path.mkdir(parents=True, exist_ok=True)

def get_file_mapping(directory):
    """–°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å {–∏–º—è_–±–µ–∑_—Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è: –ø–æ–ª–Ω–æ–µ_–∏–º—è_—Ñ–∞–π–ª–∞}"""
    mapping = {}
    for file_path in directory.iterdir():
        if file_path.is_file():
            name_without_ext = file_path.stem
            mapping[name_without_ext] = file_path.name
    return mapping

def get_pixel_perfect_names(labels_path):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ —Å pixel-perfect –º–∞—Å–∫–∞–º–∏"""
    df = pd.read_csv(labels_path)
    pixel_perfect_names = set()
    for filename in df['filename']:
        pixel_perfect_names.add(Path(filename).stem)
    return pixel_perfect_names

def preprocess_for_model(image, target_size):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–∏"""
    # Resize
    image_resized = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)
    # Normalize
    image_norm = image_resized.astype(np.float32) / 255.0
    # Convert to tensor format: (C, H, W)
    image_tensor = torch.from_numpy(image_norm).permute(2, 0, 1)
    return image_tensor

def predict_mask(model, image_path, target_size, device):
    """–ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–∫–∏ –æ—Ç –º–æ–¥–µ–ª–∏"""
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image = cv2.imread(str(image_path))
    if image is None:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    original_shape = image.shape[:2]
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏
    image_tensor = preprocess_for_model(image, target_size)
    image_tensor = image_tensor.unsqueeze(0).to(device)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    with torch.no_grad():
        prediction = model.predict(image_tensor)
        
        # === –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–µ–Ω–∑–æ—Ä–∞ –≤ NumPy ===
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤—ã—Ö–æ–¥–∞ –º–æ–¥–µ–ª–∏
        if isinstance(prediction, torch.Tensor):
            prediction = prediction.cpu()
        
        if isinstance(prediction, torch.Tensor):
            prediction = prediction.numpy()
        # =================================================
        
        # –¢–µ–ø–µ—Ä—å prediction - —ç—Ç–æ numpy array
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ prediction –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É (1, H, W) –∏–ª–∏ (1, 1, H, W) –∏–ª–∏ (H, W)
        if prediction.ndim == 4:
            # (B, C, H, W) -> –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
            prediction = prediction[0, 0]
        elif prediction.ndim == 3:
            # (B, H, W) -> –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –±–∞—Ç—á
            prediction = prediction[0]
        # –ï—Å–ª–∏ ndim == 2, —Ç–æ —ç—Ç–æ —É–∂–µ (H, W)
        
        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]
        prediction = np.clip(prediction, 0, 1)
        
    # Resize –æ–±—Ä–∞—Ç–Ω–æ –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É
    pred_mask = (prediction * 255).astype(np.uint8)
    pred_mask_resized = cv2.resize(pred_mask, (original_shape[1], original_shape[0]), 
                                   interpolation=cv2.INTER_LINEAR)
    return pred_mask_resized

def augment_image_and_mask(image, mask, seed=None):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é –ª—ë–≥–∫—É—é –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏ –º–∞—Å–∫–µ"""
    if seed is not None:
        random.seed(seed)
        np.random.seed(seed)
    
    augmented_image = image.copy()
    augmented_mask = mask.copy()
    
    aug_type = random.choice(['hflip', 'vflip', 'rotate'])
    
    if aug_type == 'hflip':
        augmented_image = cv2.flip(augmented_image, 1)
        augmented_mask = cv2.flip(augmented_mask, 1)
        
    elif aug_type == 'vflip':
        augmented_image = cv2.flip(augmented_image, 0)
        augmented_mask = cv2.flip(augmented_mask, 0)
        
    elif aug_type == 'rotate':
        angle = random.uniform(-15, 15)
        h, w = image.shape[:2]
        center = (w // 2, h // 2)
        
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        augmented_image = cv2.warpAffine(augmented_image, M, (w, h))
        augmented_mask = cv2.warpAffine(augmented_mask, M, (w, h))
    
    return augmented_image, augmented_mask, aug_type

def main():
    global images_dir, image_mapping, annotations_by_name
    
    # 1. –°–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫—É images
    images_dir = SOURCE_DIR / "images"
    if not images_dir.exists():
        raise FileNotFoundError(f"–ü–∞–ø–∫–∞ {images_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
    
    image_mapping = get_file_mapping(images_dir)
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(image_mapping)} —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ images")
    
    # 2. –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Å pixel-perfect –º–∞—Å–∫–∞–º–∏
    labels_path = SOURCE_DIR / "labels.csv"
    pixel_perfect_names = get_pixel_perfect_names(labels_path)
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(pixel_perfect_names)} —Ñ–∞–π–ª–æ–≤ —Å pixel-perfect –º–∞—Å–∫–∞–º–∏")
    
    # 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã –±–µ–∑ pixel-perfect –º–∞—Å–æ–∫ (–¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è)
    all_names = set(image_mapping.keys())
    names_to_improve = list(all_names - pixel_perfect_names)
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(names_to_improve)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª—å—é")
    
    # 4. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print("\n–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model = load_unet_attention()
    model.to(DEVICE)
    model.eval()
    print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {DEVICE}")

    dataset_num = int(input("Enter dataset number: "))

    # 5. –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —É—á–µ—Ç–æ–º alpha
    output_dir = Path(f"./datasets/{DATASET_NAME}_H{dataset_num}")
    output_images_train = output_dir / "images" / "train"
    output_images_val = output_dir / "images" / "val"
    output_masks_train = output_dir / "masks" / "train"
    output_masks_val = output_dir / "masks" / "val"
    
    copy_or_create_dirs(output_images_train, output_images_val, 
                       output_masks_train, output_masks_val)
    
    # 6. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–∞—Å–æ–∫
    train_files, val_files = train_test_split(
        names_to_improve,
        train_size=TRAIN_VAL_SPLIT,
        random_state=RANDOM_SEED,
        shuffle=True
    )
    
    print(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(train_files)} train —Ñ–∞–π–ª–æ–≤ –∏ {len(val_files)} val —Ñ–∞–π–ª–æ–≤...")
    
    def process_and_save(name_list, img_dest, mask_dest, split_name):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª—ã, —Å–æ–∑–¥–∞–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–µ –º–∞—Å–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç"""
        print(f"\n{split_name}: —Å–æ–∑–¥–∞–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω—ã—Ö –º–∞—Å–æ–∫...")
        
        for name in name_list:
            real_filename = image_mapping[name]
            src_image_path = images_dir / real_filename
            src_mask_path = SOURCE_DIR / "masks" / real_filename
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
            if not src_image_path.exists():
                print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {src_image_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                continue
            if not src_mask_path.exists():
                print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ú–∞—Å–∫–∞ {src_mask_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                continue
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –º–∞—Å–∫–∏
            image = cv2.imread(str(src_image_path))
            original_mask = cv2.imread(str(src_mask_path), cv2.IMREAD_GRAYSCALE)
            
            if image is None or original_mask is None:
                print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –¥–ª—è {name}")
                continue
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
            try:
                predicted_mask = predict_mask(model, src_image_path, MODEL_INPUT_SIZE, DEVICE)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {name}: {e}")
                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–∞—Å–∫—É
                predicted_mask = np.zeros_like(original_mask)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–π –º–∞—Å–∫–∏
            # original_mask * alpha + predicted_mask * (1 - alpha)
            hybrid_mask = cv2.addWeighted(
                original_mask, ALPHA,
                predicted_mask, (1 - ALPHA),
                0
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≥–∏–±—Ä–∏–¥–Ω–æ–π –º–∞—Å–∫–∏
            dest_image_path = img_dest / real_filename
            mask_filename = Path(real_filename).stem + ".png"
            dest_mask_path = mask_dest / mask_filename
            
            try:
                cv2.imwrite(str(dest_image_path), image)
                cv2.imwrite(str(dest_mask_path), hybrid_mask)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {name}: {e}")
                continue
            
            if len(name_list) <= 5:
                print(f"  {name}: –≥–∏–±—Ä–∏–¥–Ω–∞—è –º–∞—Å–∫–∞ —Å–æ–∑–¥–∞–Ω (alpha={ALPHA})")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω—ã—Ö –º–∞—Å–æ–∫
    process_and_save(train_files, output_images_train, output_masks_train, "Hybrid train")
    process_and_save(val_files, output_images_val, output_masks_val, "Hybrid val")
    
    # 7. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ù–ï –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ BASELINE
    print("\n–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤ –∏–∑ BASELINE...")
    
    baseline_train_dir = BASELINE_DIR / "images" / "train"
    baseline_train_files = [f for f in baseline_train_dir.iterdir() 
                           if f.is_file() and "_aug" not in f.name]
    
    for image_file in baseline_train_files:
        # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        src_image = image_file
        dest_image = output_images_train / image_file.name
        if not dest_image.exists():
            image = cv2.imread(str(src_image))
            cv2.imwrite(str(dest_image), image)
        
        # –ö–æ–ø–∏—Ä—É–µ–º –º–∞—Å–∫—É
        mask_name = image_file.stem + ".png"
        src_mask = BASELINE_DIR / "masks" / "train" / mask_name
        dest_mask = output_masks_train / mask_name
        
        if src_mask.exists() and not dest_mask.exists():
            mask = cv2.imread(str(src_mask), cv2.IMREAD_GRAYSCALE)
            cv2.imwrite(str(dest_mask), mask)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ BASELINE
    baseline_val_dir = BASELINE_DIR / "images" / "val"
    baseline_val_files = [f for f in baseline_val_dir.iterdir() if f.is_file()]
    
    for image_file in baseline_val_files:
        # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        src_image = image_file
        dest_image = output_images_val / image_file.name
        if not dest_image.exists():
            image = cv2.imread(str(src_image))
            cv2.imwrite(str(dest_image), image)
        
        # –ö–æ–ø–∏—Ä—É–µ–º –º–∞—Å–∫—É
        mask_name = image_file.stem + ".png"
        src_mask = BASELINE_DIR / "masks" / "val" / mask_name
        dest_mask = output_masks_val / mask_name
        
        if src_mask.exists() and not dest_mask.exists():
            mask = cv2.imread(str(src_mask), cv2.IMREAD_GRAYSCALE)
            cv2.imwrite(str(dest_mask), mask)
    
    print(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(baseline_train_files)} train –∏ {len(baseline_val_files)} val —Ñ–∞–π–ª–æ–≤ –∏–∑ BASELINE")
    
    # 8. –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (—Ç–æ–ª—å–∫–æ train)
    def apply_final_augmentation(img_dir, mask_dir):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –∫–æ –≤—Å–µ–º —Ñ–∞–π–ª–∞–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        print(f"\n–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫ {img_dir}...")
        
        image_files = [f for f in img_dir.iterdir() if f.is_file() and "_aug" not in f.name]
        
        for image_file in image_files:
            image = cv2.imread(str(image_file))
            mask_file = mask_dir / (image_file.stem + ".png")
            
            if not mask_file.exists():
                continue
            
            mask = cv2.imread(str(mask_file), cv2.IMREAD_GRAYSCALE)
            
            for i in range(NUM_AUGMENTATIONS):
                aug_seed = RANDOM_SEED + hash(image_file.stem) % 1000 + i
                
                aug_image, aug_mask, aug_type = augment_image_and_mask(
                    image, mask, seed=aug_seed
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏
                aug_image_name = f"{image_file.stem}_aug{i}{image_file.suffix}"
                aug_mask_name = f"{image_file.stem}_aug{i}.png"
                
                cv2.imwrite(str(img_dir / aug_image_name), aug_image)
                cv2.imwrite(str(mask_dir / aug_mask_name), aug_mask)
    
    apply_final_augmentation(output_images_train, output_masks_train)
    
    # 9. –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ! –î–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω:")
    print(f"   - –ü—É—Ç—å: {output_dir}")
    print(f"   - Alpha: {ALPHA}")
    
    train_images = list(output_images_train.iterdir())
    val_images = list(output_images_val.iterdir())
    total_images = len(train_images) + len(val_images)
    
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   - Train: {len(train_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"   - Val:   {len(val_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"   - Total: {total_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

if __name__ == "__main__":
    main()