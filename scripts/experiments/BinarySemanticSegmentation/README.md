## Binary Semantic Segmentation (BSS)


В этом эксперименте обучается модель UNet для задачи семантической сегментации фона в канализационных трубах. Так как найти размеченный датасет не удалось, было создано 2 датасета из уже существующего, но предназначенного для задачи детекции 6-ти классов.

  
1. **Pipe Box Segmentation (PBS)** - создан с помощью заливки детекционных боксов оригинального датасета. Данных получилось много, но все они низкого качества.
2. **Pipe Segmentation (PS)** - создан с помощью ручной разметки. Фон и объекты выделены аккуратными контурами, однако размер датасета в 50-100 раз уступает PBS. Легко переобучить модель.

### Задача

Получить наибольшие метрики IoU и Dice. Напомню их значение и формулы.

**IoU (или Jaccard Index)**

Метрика, показывающая, насколько сильно предсказанная область пересекается с истинной.

- Значение от **0 до 1**
- `1` — идеальное совпадение
- `0` — полное несовпадение

$$
IoU = \frac{|Prediction \cap GroundTruth|}{|Prediction \cup GroundTruth|}
$$

**Dice (или Sørensen–Dice coefficient)** 

Метрика измеряет схожесть двух множеств. Он чуть *мягче* к небольшим ошибкам, чем IoU.

- Значение от **0 до 1**
- `1` — идеальное совпадение
- `0` — полное несовпадение

$$
Dice = \frac{2 \times |Prediction \cap GroundTruth|}{|Prediction| + |GroundTruth|}
$$

#### Проблема

В нашем проекте есть небольшая проблема. Наши маски являются недостаточно информативными. Они только указывают возможное нахождение объекта, но не абсолютно точное, поэтому метрики IoU и Dice бесполезными при валидации. Опорной метрикой для оценки в течении обучения будет Recall.

### Конфигурация эксперимента

Скачиваем один из датасетов и распаковываем в `datasets/`:

1. [Deformation](https://drive.google.com/file/d/18vIr-kyKG3bxZd7sIsB6h_MmFDujMOxI/view?usp=sharing)
2. [Deposition](https://drive.google.com/file/d/10Q4bG7Rx7FYhgQ9oPccfx6L_dmVYo2zO/view?usp=sharing)
3. [Disconnect](https://drive.google.com/file/d/1etdRvihZfpaw2sphg85hg0wawm5kpoHJ/view?usp=sharing)
4. [Obstacle](https://drive.google.com/file/d/1c2vILrX9NTYukamw2As78rQTlWn04Noh/view?usp=sharing)

Получаем такую структуру

```text
datasets/
|-- <dataset_name>/
|   |-- images/
|   |-- masks/
|   |-- labels.csv
```

Запускаем скрипт `scripts/tools/preprocess_dataset.py` (указываем имя скачанного датасета). В директории `datasets/` появятся еще два датаета:
 - <dataset_name>_BASELINE - маленький датасет для обучения baseline модели
 - <dataset_name>_EVAL - датасет для оценки модели

Базовая конфигурация завершена.

### Ход и объяснение эксперимента

Базовое объяснение того, что происходит:

1. Были созданы 4 небольших датасета для предсказания какого-то отдельного класса
2. 200 картинок из каждого датасета были размечены и разделены на BASELINE и EVAL группу

Объяснение того, что будет происходить

1. Обучаем модель на BASELINE датасете. 20-40 эпох достаточно, необходимо получить высокие метрики на EVAL группе.
2. Улучшаем этой моделью плохие маски (создаётся новый датасет).
3. Обучаем нормальную модель уже на улучшенном датасете.

#### Что делать?

##### Меняем `config.yaml`

```yaml
seed: 42

epochs: 1
learning_rate: 0.0001
batch_size: 2
criterion: 
  name: TverskyLoss
  args:
    alpha: 0.1
    beta: 0.9
    smooth: 1
    mode: binary
    from_logits: True

train_dataset: <dataset_name>_BASELINE # Замените на своё
evaluation_dataset: <dataset_name>_EVAL # Замените на своё
image_size: [704, 512]
model:
  name: UNetAttention
  args:
    encoder_name: resnet34
    encoder_weights: imagenet
    in_channels: 3
    classes: 1

val_per_epoch: 1
visualization_samples: 30
```

Обучаем baseline модель и сохраняем её. 

##### Создаём гибридный датасет

Запускаем `scripts/tools/make_hybrid_dataset.py`. У вас в директории `datasets/` появится еще один датасет `<dataset_name>_H<number>`. В первый раз указываем номер датасета 1, во второй раз 2 и т.д. Далее будет объяснено, зачем создавать несколько датасетов.

##### Обучаем новую (чистую) модель на модифицированных данных

Меняем в `config.yaml` строку:

```yaml
train_dataset: <dataset_name>_BASELINE # Замените на своё
``` 

на

```yaml
train_dataset: <dataset_name>_H<number> # Замените на своё
```

Запускаем обучение и играемся с параметрами.

##### Продолжение

Если хочется попробовать нечто необычное, то можно использовать только что обученную модель для очередного улучшения данных. Снова запускаем `scripts/tools/make_hybrid_dataset.py` и уже указываем последнюю модель (теперь она наш baseline) и новый номер датасета (иначе старый датасет перезапишется). Теперь у нас очередной улучшенный датасет, на котором снова можно обучать модель. Однако много итераций делать не советую, так как метрики могут упасть.
